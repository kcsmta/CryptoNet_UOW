\section{Introduction}

The two fields of "cryptography" and "machine learning" studies have produced great results in recent years. Neural networks (a specific class of machine learning algorithms) have reached levels of accuracy never obtained with other methods in tasks such as image classification and speech recognition. On the other hand, cryptography research has produced a new set of cryptographic scheme that preserve most of the interesting statistical structure of the data \cite{safeai}. These schemes are called homomorphic encryption: they were first proposed in 1978 \cite{firstHomEnc}, and the first Fully Homomorphic algorithm was found in 2009 \cite{10.1007/978-3-642-29011-4_28}. Since then other algorithms have been discovered that allow greater speed by sacrificing part of the flexibility of the cryptographic scheme, and now the intersection between these two research field (homomorphic algorithms and deep learning) is revolutionizing the world of cloud computing. The use of this technology has advantages: for example, an encrypted neural network is protected from those who might want to steal it. It allows the decentralization of the AI, making it possible to be trained in insecure environments without risk by the owner of the network. Moreover, many people are frightened by the possibility that an artificial superintelligence can harm humanity. Some experts, like Stephen Hawking, Elon Musk and others have signed an open letter that focuses on these issues, calling for greater responsibility during the development of artificial intelligence \cite{open-letter}. The application of cryptography to neural networks can represent a potential technical solution to this problem: if the AI is encrypted, then from its point of view the whole external world is encrypted. So the human who has the key to decipher the neural network has control over his intelligence: he can decrypt individual predictions that it makes, without having to decrypt the network itself \cite{safeai}. But the main application addressed by this project is Data Privacy. Progress in fields such as stock market efficiency is hampered by the lack of open participations, due to the privacy of datasets. In fact, most stock market data are not publicly available, because it would be an economic loss to disclose them, so the owners usually keep them private. Using cryptography, however, it is possible to publish a datasets for training a model without giving away valuable data \cite{numerai}. Beside training, cryptography is also useful during the inference stage. Take for example a hospital that would like to use a cloud service to predict the probability of readmission of a patient within the next 30 days. In order to use this service without violating the ethical and legal requirements regarding the confidentiality of patient information, the hospital can take advantage of CryptoNet, the algorithm described in this report.

\subsection{Roadmap}

In this report we will analyze the work that we done on the CryptoNets. The project is based on \cite{dowlin2016cryptonets}, developed by Microsoft researchers. The report is structured as follows: in Section 2 we analyze how the cryptographic algorithm works. In Section 3 we give a description of the neural network and of some problems arising in the use of the cryptographic scheme. In Section 4 we introduce the Microsoft software SEAL library used in this project and to follow, in Section 5, we describe the rest of the code developed. The report closes with the presentation of the results obtained in Section 6 and the conclusion in Section 7.